{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72b64b4a",
   "metadata": {},
   "source": [
    "\n",
    "# Sprachmodell-Anfrage mit modernem OpenAI Client und GPT4All-Embeddings\n",
    "\n",
    "Dieses Jupyter Notebook demonstriert, wie man mit Hilfe des OpenAI-Clients und GPT4All-Embeddings\n",
    "eine umfassende Textanalyse durchführt. Es verwendet den Hochschulinternen API-Endpunkt.\n",
    "\n",
    "## Überblick\n",
    "\n",
    "In diesem Notebook lernen Sie:\n",
    "1. Wie man die OpenAI-Bibliothek und GPT4All installiert\n",
    "2. Wie man den modernen OpenAI Client mit benutzerdefinierten Endpunkten konfiguriert\n",
    "3. Wie man lokale Embeddings mit GPT4All generiert\n",
    "4. Wie man lange Texte analysiert und mit OpenAI integriert\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a702b7",
   "metadata": {},
   "source": [
    "## 1. Installation der erforderlichen Pakete\n",
    "\n",
    "Zunächst müssen wir sicherstellen, dass alle notwendigen Bibliotheken installiert sind.\n",
    "\n",
    "Auf AI.H2.de ist das nicht nötig, da der JupyterHub die Bibliotheken schon vorinstalliert.\n",
    "\n",
    "In anderen Umgebungen muss das noch nachgeholt werden. Führen Sie die folgende Zelle aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d8dbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"openai>=1.0.0\" gpt4all langchain langchain_community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8280751a",
   "metadata": {},
   "source": [
    "## 2. Initialisierung des modernen OpenAI Clients\n",
    "\n",
    "Wir importieren die `OpenAI`-Klasse und erstellen einen Client mit unseren Konfigurationsparametern.\n",
    "\n",
    "**Wichtige Parameter:**\n",
    "- `api_key`: Der Authentifizierungsschlüssel für die API\n",
    "- `base_url`: Die Basis-URL des API-Servers (ersetzt das frühere `api_base`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59999fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initialisierung des Clients mit benutzerdefinierten Parametern\n",
    "client = OpenAI(\n",
    "    api_key=\"sk-1234\",            # API-Key für die Authentifizierung\n",
    "    base_url=\"https://ai.h2.de/llm\"  # Benutzerdefinierter Endpunkt\n",
    ")\n",
    "\n",
    "print(f\"Moderner OpenAI Client initialisiert mit Basis-URL: {client.base_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b7110f",
   "metadata": {},
   "source": [
    "## 3. Einrichtung des GPT4All-Embeddings-Modells\n",
    "\n",
    "Wir initialisieren das GPT4All-Embeddings-Modell. Dieses Modell ist besonders geeignet für:\n",
    "- Lokale Text-Einbettungen\n",
    "- Effiziente Verarbeitung langer Texte\n",
    "- Privatsphäre-gerechte Textanalyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415af18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt4all import Embed4All\n",
    "\n",
    "# Initialisierung des Embeddings-Modells\n",
    "embedder = Embed4All()\n",
    "\n",
    "print(\"GPT4All-Embeddings-Modell erfolgreich initialisiert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd91e29a",
   "metadata": {},
   "source": [
    "## 4. Generierung von Embeddings für einen langen Text\n",
    "\n",
    "In diesem Abschnitt demonstrieren wir, wie man Embeddings für einen langen Text generiert. Das Modell verarbeitet automatisch Texte, die länger als der Kontext sind, indem es sie in Chunks unterteilt und die Embeddings durchschnittlich berechnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b4ba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel für einen langen Text (z.B. ein Artikel oder Dokument)\n",
    "long_text = \"\"\"\n",
    "Die Künstliche Intelligenz (KI) ist eine der wichtigsten Technologien des 21. Jahrhunderts.\n",
    "Sie revolutioniert Bereiche wie Gesundheitswesen, Finanzwesen, Produktion und Vertrieb.\n",
    "KI-Systeme können komplexe Muster erkennen, Vorhersagen treffen und selbstständig lernen.\n",
    "Dabei spielen verschiedene Techniken wie neuronale Netze, maschinelles Lernen und tiefes Lernen\n",
    "eine zentrale Rolle. Die Entwicklung fortschreitender KI-Modelle wie GPT-4 oder Claude\n",
    "öffnet neue Möglichkeiten für natürlichsprachliche Interaktionen und intelligente Systeme.\n",
    "Trotz der Vorteile gibt es auch Herausforderungen wie Datensicherheit, Ethik und\n",
    "die Notwendigkeit menschlicher Überwachung.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26604cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generieren der Embeddings\n",
    "embeddings = embedder.embed(long_text, long_text_mode=\"mean\")\n",
    "\n",
    "# Ausgabe der Embedding-Größe\n",
    "print(f\"Generierte Embeddings haben die Dimension: {len(embeddings)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d181f76",
   "metadata": {},
   "source": [
    "## 5. Vorbereitung für kontextbasierte Suche\n",
    "\n",
    "Wir können Embeddings nutzen, um relevante Passagen aus einem umfangreichen Dokument zu finden und den Kontext für die Anfrage zu erweitern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4636f8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Beispiel für ein längeres Dokument (in der Praxis könnten dies mehrere Dokumente sein)\n",
    "extended_document = \"\"\"\n",
    "Die Künstliche Intelligenz (KI) ist eine der wichtigsten Technologien des 21. Jahrhunderts.\n",
    "Sie revolutioniert Bereiche wie Gesundheitswesen, Finanzwesen, Produktion und Vertrieb.\n",
    "KI-Systeme können komplexe Muster erkennen, Vorhersagen treffen und selbstständig lernen.\n",
    "\n",
    "Neuronale Netze sind ein zentrales Konzept in der KI. Sie bestehen aus Schichten von Neuronen,\n",
    "die miteinander verbunden sind und komplexe Berechnungen durchführen können. Deep Learning,\n",
    "eine Unterkategorie des maschinellen Lernens, nutzt tiefe neuronale Netze mit vielen\n",
    "verborgenen Schichten, um besonders komplexe Aufgaben zu bewältigen.\n",
    "\n",
    "Maschinelles Lernen ermöglicht es Computern, aus Erfahrungen zu lernen und sich anzupassen,\n",
    "ohne explizit programmiert zu werden. Es gibt verschiedene Ansätze: überwachtes Lernen,\n",
    "unüberwachtes Lernen und bestärkendes Lernen.\n",
    "\n",
    "Moderne KI-Modelle wie GPT-4 oder Claude basieren auf Transformer-Architekturen, die\n",
    "besonders effektiv bei der Verarbeitung natürlicher Sprache sind. Diese Modelle werden\n",
    "mit enormen Datenmengen trainiert und können beeindruckende Ergebnisse bei Textgenerierung,\n",
    "Übersetzung und Inhaltsanalyse erzielen.\n",
    "\n",
    "Die Herausforderungen der KI umfassen ethische Bedenken, Datenschutz, Fairness und Transparenz.\n",
    "Es ist wichtig, dass KI-Systeme verantwortungsvoll entwickelt und eingesetzt werden.\n",
    "\"\"\"\n",
    "\n",
    "# Text in Chunks aufteilen für detailliertere Analyse\n",
    "def split_into_chunks(text, chunk_size=150):\n",
    "    \"\"\"Text in überlappende Chunks aufteilen\"\"\"\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), chunk_size // 2):\n",
    "        chunk = ' '.join(words[i:i + chunk_size])\n",
    "        chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "document_chunks = split_into_chunks(extended_document)\n",
    "print(f\"Dokument wurde in {len(document_chunks)} Chunks aufgeteilt\")\n",
    "\n",
    "# Embeddings für jeden Chunk generieren\n",
    "chunk_embeddings = [embedder.embed(chunk) for chunk in document_chunks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bf2284",
   "metadata": {},
   "source": [
    "## 6. Kontexterweiterung für die OpenAI-Anfrage\n",
    "\n",
    "Mit Hilfe von Embeddings können wir die relevantesten Teile des Dokuments identifizieren\n",
    "und sie als Kontext in unsere Anfrage an OpenAI einbeziehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a339ac8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel-Anfrage\n",
    "query = \"Welche technischen Grundlagen stehen hinter modernen KI-Systemen?\"\n",
    "query_embedding = embedder.embed(query)\n",
    "\n",
    "# Ähnlichkeiten zu allen Chunks berechnen\n",
    "similarities = [cosine_similarity([query_embedding], [emb])[0][0] for emb in chunk_embeddings]\n",
    "\n",
    "# Die relevantesten Chunks auswählen (Top-2)\n",
    "top_chunk_indices = np.argsort(similarities)[-2:]\n",
    "relevant_context = \"\\n\".join([document_chunks[i] for i in top_chunk_indices])\n",
    "\n",
    "print(f\"Relevantester Kontext ausgewählt mit Ähnlichkeitswerten: {[similarities[i] for i in top_chunk_indices]}\")\n",
    "\n",
    "# Senden einer Anfrage an das OpenAI-Modell mit erweitertem Kontext\n",
    "context_enhanced_prompt = f\"\"\"\n",
    "Hier ist relevanter Kontext zu der Anfrage:\n",
    "\n",
    "{relevant_context}\n",
    "\n",
    "Basierend auf diesem Kontext, beantworte bitte folgende Frage:\n",
    "{query}\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"Llama3.3\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Du bist ein hilfreicher Assistent für KI-Themen.\"},\n",
    "        {\"role\": \"user\", \"content\": context_enhanced_prompt}\n",
    "    ],\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "# Formatierte Ausgabe der Antwort\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "markdown_output = f\"\"\"\n",
    "## Antwort mit erweitertem Kontext:\n",
    "\n",
    "> {completion.choices[0].message.content}\n",
    "\n",
    "### Metadaten:\n",
    "- **Modell**: {completion.model}\n",
    "- **Completion-Tokens**: {completion.usage.completion_tokens}\n",
    "- **Prompt-Tokens**: {completion.usage.prompt_tokens}\n",
    "- **Gesamtanzahl der Tokens**: {completion.usage.total_tokens}\n",
    "\"\"\"\n",
    "display(Markdown(markdown_output))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
